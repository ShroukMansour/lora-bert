{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install peft","metadata":{"execution":{"iopub.status.busy":"2024-08-14T13:26:57.858928Z","iopub.execute_input":"2024-08-14T13:26:57.859666Z","iopub.status.idle":"2024-08-14T13:27:12.901914Z","shell.execute_reply.started":"2024-08-14T13:26:57.859606Z","shell.execute_reply":"2024-08-14T13:27:12.900812Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting peft\n  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.42.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.32.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.23.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.5.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.12.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom peft import PeftModel, PeftConfig, LoraConfig, TaskType, get_peft_model\nfrom transformers import TrainingArguments, Trainer, AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding\nimport time\n\nid2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\nlabel2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n\n\nmodel= AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", id2label=id2label, label2id=label2id)\ndataset = load_dataset(\"rotten_tomatoes\")\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-08-14T13:42:47.468214Z","iopub.execute_input":"2024-08-14T13:42:47.469074Z","iopub.status.idle":"2024-08-14T13:42:49.111272Z","shell.execute_reply.started":"2024-08-14T13:42:47.469015Z","shell.execute_reply":"2024-08-14T13:42:49.110260Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 8530\n    })\n    validation: Dataset({\n        features: ['text', 'label'],\n        num_rows: 1066\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 1066\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"checkpoint = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T13:32:23.688615Z","iopub.execute_input":"2024-08-14T13:32:23.688993Z","iopub.status.idle":"2024-08-14T13:32:23.798878Z","shell.execute_reply.started":"2024-08-14T13:32:23.688964Z","shell.execute_reply":"2024-08-14T13:32:23.797882Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def tokenizer_func(input):\n  return tokenizer(input[\"text\"],  truncation=True)\n\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\ndata_tokenized = dataset.map(tokenizer_func, batched=True)\n\ntrain_data_tokenized = data_tokenized[\"train\"].remove_columns([\"text\"]).rename_column(\"label\", \"labels\")\nval_data_tokenized = data_tokenized[\"validation\"].remove_columns([\"text\"]).rename_column(\"label\", \"labels\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T13:41:36.742308Z","iopub.execute_input":"2024-08-14T13:41:36.742926Z","iopub.status.idle":"2024-08-14T13:41:37.819039Z","shell.execute_reply.started":"2024-08-14T13:41:36.742894Z","shell.execute_reply":"2024-08-14T13:41:37.818075Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8530 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b040983523448d9b7397ec254c84b54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1066 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"127b0616ea4442319420e9f40f0e2857"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1066 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b917c34c0634b89be01f16d3bfc4b07"}},"metadata":{}}]},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=8, # rank - see hyperparameter section for more details\n    lora_alpha=32, # scaling factor - see hyperparameter section for more details\n    target_modules=[\"q_lin\", \"v_lin\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=TaskType.SEQ_CLS\n)\n\npeft_model = get_peft_model(model, lora_config)\npeft_model.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-08-14T13:41:40.937189Z","iopub.execute_input":"2024-08-14T13:41:40.938018Z","iopub.status.idle":"2024-08-14T13:41:40.962122Z","shell.execute_reply.started":"2024-08-14T13:41:40.937986Z","shell.execute_reply":"2024-08-14T13:41:40.961229Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"trainable params: 739,586 || all params: 67,694,596 || trainable%: 1.0925\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"output_dir = f'./rotten-tomatoes-classification-training-{str(int(time.time()))}'\n\ntraining_args = TrainingArguments(\n    output_dir=output_dir,\n    learning_rate=1e-5,\n    logging_steps=1,\n     max_steps=10\n)\n\ntrainer = Trainer(\n    model=peft_model,\n    args=training_args,\n    train_dataset=train_data_tokenized,\n    eval_dataset=val_data_tokenized,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T13:42:52.535859Z","iopub.execute_input":"2024-08-14T13:42:52.536244Z","iopub.status.idle":"2024-08-14T13:42:53.669251Z","shell.execute_reply.started":"2024-08-14T13:42:52.536213Z","shell.execute_reply":"2024-08-14T13:42:53.668442Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T13:43:41.596129Z","iopub.execute_input":"2024-08-14T13:43:41.596757Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}